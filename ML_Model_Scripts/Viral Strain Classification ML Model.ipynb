{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d08681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:  (8893, 512)\n",
      "Shape of y: (8893,)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from concrete.ml.sklearn import LogisticRegression, LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression as skLR\n",
    "from sklearn.linear_model import LinearRegression as skLinear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def feature_selection(x, opt = \"\", var_percent = 0.8, n_features = 30):\n",
    "    if opt == \"var\":\n",
    "        print(\"\\nUsing variance threshold feature selection...\")\n",
    "        # Remove all features that have low variance in more than (percent)% of the samples.\n",
    "        #percent = .80\n",
    "        sel = VarianceThreshold(threshold=(var_percent * (1 - var_percent)))\n",
    "        print(\"Shape of X: \", x.shape)\n",
    "        #print(x.iloc[0])\n",
    "        x = sel.fit_transform(x)\n",
    "        print(\"After feature selection: \", len(x[0]), \" features\")\n",
    "        #print(x[0])\n",
    "    elif opt == \"kbest\":\n",
    "        print(\"\\nUsing K best features feature selection...\")\n",
    "        print(\"Shape of x before selection: \", x.shape)\n",
    "        x = SelectKBest(chi2, k=n_features).fit_transform(x, y)\n",
    "        print(\"Shape of x after selection: \", x.shape)\n",
    "    elif opt == \"pca\":\n",
    "        print(\"\\nUsing PCA feature selection...\")\n",
    "        x_scaled = StandardScaler().fit_transform(x)\n",
    "        pca = PCA(n_components=n_features)\n",
    "        pca_features = pca.fit_transform(x_scaled)\n",
    "        print('Shape before PCA: ', x_scaled.shape)\n",
    "        print('Shape after PCA: ', pca_features.shape)\n",
    "        x = pca_features\n",
    "    else:\n",
    "        print(\"\")\n",
    "    return x\n",
    "\n",
    "#select set option\n",
    "set = -1\n",
    "\n",
    "#import the dataset here (GISAID; try downloading individual FASTA files if di talaga kaya idownload yung EPISET)\n",
    "#if(set == -1):\n",
    "#    dataset_name = \"AFHE DATASET (05-04-2023).csv\"\n",
    "#elif(set == 0):\n",
    "#    dataset_name = \"ADJUSTED DATASET (05-04-2023).csv\"\n",
    "#else:\n",
    "#    dataset_name = \"ADJUSTED DOWNSIZED DATASET (05-04-2023).csv\"\n",
    "#dataset = pd.read_csv(dataset_name)\n",
    "\n",
    "dataset = pd.read_csv(\"AFHE DATASET (05-18-2023).csv\")\n",
    "\n",
    "#print(dataset['Lineage'].value_counts())\n",
    "\n",
    "#remove \"EPI_ISL_\" from ID\n",
    "#new_ID_col = []\n",
    "#for i in range(0, len(dataset['Accession ID'])):\n",
    "#    new_ID_col.append(str(dataset['Accession ID'].loc[i].replace(\"EPI_ISL_\", \"\")))\n",
    "#dataset['Accession ID'] = new_ID_col\n",
    "\n",
    "feature_cols = [c for c in dataset.columns[2:]]\n",
    "#print(feature_cols)\n",
    "\n",
    "x = dataset.loc[:,feature_cols].values #must be floats\n",
    "y = dataset.loc[:,'Lineage'].values #must be integers\n",
    "\n",
    "#print(x)\n",
    "#print(y)\n",
    "\n",
    "# Preprocessing with labels for the lineage\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "x = x.astype(float)\n",
    "\n",
    "print(\"Shape of x: \", x.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96102a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using variance threshold feature selection...\n",
      "Shape of X:  (8893, 512)\n",
      "After feature selection:  512  features\n",
      "\n",
      "Using K best features feature selection...\n",
      "Shape of x before selection:  (8893, 512)\n",
      "Shape of x after selection:  (8893, 15)\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection Cell (ensemble attempted)\n",
    "\n",
    "x = feature_selection(x, \"var\", var_percent = 0.80)\n",
    "x = feature_selection(x, \"kbest\", n_features = 15)\n",
    "#x = feature_selection(x, \"pca\", n_features = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97925861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=.20) #stratify=y\n",
    "\n",
    "st_x = StandardScaler()\n",
    "X_train = st_x.fit_transform(X_train)\n",
    "X_test = st_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "06358296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sklearn:  98.70713884204609 %\n"
     ]
    }
   ],
   "source": [
    "# Initialize SKLearn model\n",
    "\n",
    "skmodel = skLR(C=1)\n",
    "skmodel.fit(X_train,y_train)\n",
    "skmodel.predict(X_test)\n",
    "print(\"Accuracy for sklearn: \", skmodel.score(X_test,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42914038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate for quantized plaintext:   97.3018549747049 %\n",
      "PREDICTION:\n",
      " [0 2 3 ... 2 3 3]\n",
      "ACTUAL:\n",
      " [0 2 3 ... 2 3 3]\n",
      "model compiled!\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and fix the number of bits to used for quantization \n",
    "model = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Run the predictions on non-encrypted data as a reference\n",
    "y_pred_clear = model.predict(X_test, execute_in_fhe = False)\n",
    "\n",
    "# Output (plaintext vs FHE):\n",
    "# print(\"In clear:  \", le.inverse_transform(y_pred_clear))\n",
    "# accuracy_score(y_test, y_pred_clear)\n",
    "print(\"Accuracy rate for quantized plaintext:  \", model.score(X_test,y_test) * 100, \"%\")\n",
    "\n",
    "#low/higly volatile accuracy may be attributed to small dataset and too many features \n",
    "#(feature selection needed and more samples are required)\n",
    "print(\"PREDICTION:\\n\", y_pred_clear)\n",
    "print(\"ACTUAL:\\n\", y_test) \n",
    "\n",
    "# Compile into a FHE model\n",
    "model.compile(x)\n",
    "print(\"model compiled!\")\n",
    "\n",
    "# Run the inference in FHE\n",
    "#y_pred_fhe = model.predict(X_test, execute_in_fhe=True)\n",
    "#print(\"Accuracy rate for quantized plaintext:  \", accuracy_score(y_test, y_pred_fhe) * 100, \"%\")\n",
    "\n",
    "#print(\"In FHE    :\", y_pred_fhe)\n",
    "#print(f\"Comparison: {int((y_pred_fhe == y_pred_clear).sum()/len(y_pred_fhe)*100)}% similar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "298f0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit learn AUROC (One vs Rest):  0.9243186835391495\n",
      "Scikit learn AUROC (One vs One):  0.9165580117168153\n",
      "Concrete-ML AUROC (One vs Rest):  0.668578831326595\n",
      "Concrete-ML AUROC (One vs One):  0.6685178414348673\n"
     ]
    }
   ],
   "source": [
    "#Get AUC for multiclass\n",
    "#NOTE WE HAVE A MULTICLASS BUT NOT MULTILABEL PROBLEM. only one label selected from multiple classes is assigned\n",
    "\n",
    "print(\"Scikit learn AUROC (One vs Rest): \", roc_auc_score(y, skmodel.predict_proba(x), multi_class='ovr'))\n",
    "print(\"Scikit learn AUROC (One vs One): \", roc_auc_score(y, skmodel.predict_proba(x), multi_class='ovo'))\n",
    "\n",
    "print(\"Concrete-ML AUROC (One vs Rest): \", roc_auc_score(y, model.predict_proba(x), multi_class='ovr'))\n",
    "print(\"Concrete-ML AUROC (One vs One): \", roc_auc_score(y, model.predict_proba(x), multi_class='ovo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73d0db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Linear Regression Accuracy:  96.17107278836549 %\n",
      "Concrete-ML Linear Regression Accuracy:  42.732270862537305 %\n",
      "Sklearn Random Forest Accuracy:  98.76335019673974 %\n",
      "Concrete-ML Random Forest Accuracy:  98.25744800449691 %\n",
      "Sklearn SVC Accuracy:  98.70713884204609 %\n",
      "Concrete-ML SVC Accuracy:  97.02079820123664 %\n"
     ]
    }
   ],
   "source": [
    "from concrete.ml.sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVC as skSVC\n",
    "from concrete.ml.sklearn.rf import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "\n",
    "#SKLEARN LINEAR REGRESSION\n",
    "skmodel2 = skLinear()\n",
    "skmodel2.fit(X_train,y_train)\n",
    "skmodel2.predict(X_test)\n",
    "print(\"Sklearn Linear Regression Accuracy: \", skmodel2.score(X_test,y_test)*100,\"%\")\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train,y_train)\n",
    "model2.predict(X_test)\n",
    "print(\"Concrete-ML Linear Regression Accuracy: \", model2.score(X_test,y_test)*100,\"%\")\n",
    "\n",
    "#SKLEARN RANDOM FOREST\n",
    "skmodel3 = skRF()\n",
    "skmodel3.fit(X_train, y_train)\n",
    "skmodel3.predict(X_test)\n",
    "print(\"Sklearn Random Forest Accuracy: \",skmodel3.score(X_test,y_test)*100,\"%\")\n",
    "\n",
    "model3 = RandomForestClassifier()\n",
    "model3.fit(X_train, y_train)\n",
    "model3.predict(X_test)\n",
    "print(\"Concrete-ML Random Forest Accuracy: \",model3.score(X_test,y_test)*100,\"%\")\n",
    "\n",
    "#SKLEARN SVC\n",
    "skmodel4 = skSVC()\n",
    "skmodel4.fit(X_train, y_train)\n",
    "skmodel4.predict(X_test)\n",
    "print(\"Sklearn SVC Accuracy: \",skmodel4.score(X_test,y_test)*100,\"%\")\n",
    "\n",
    "model4 = LinearSVC()\n",
    "model4.fit(X_train, y_train)\n",
    "model4.predict(X_test)\n",
    "print(\"Concrete-ML SVC Accuracy: \",model4.score(X_test,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8b3431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.454 (0.102)\n"
     ]
    }
   ],
   "source": [
    "# prepare the cross-validation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3)\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f57e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
